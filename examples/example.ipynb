{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7518c5c9-79ab-4daa-a7af-a5c699821c3a",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Nuggetizer: A lightweight nugget-based evaluation framework for pyterrier-rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c04970-bc5a-4e55-a669-fa19abcd1574",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Introduction\n",
    "In this notebook, we demonstrate how to evaluate a Retrieval-Augmented Generation (RAG) system\n",
    "using a semantic nugget-based evaluation framework inspired by the \"AutoNuggetizer\" used in TREC 2024.\n",
    "The goal is to assess the factual informativeness of generated answers through fine-grained nugget detection\n",
    "and scoring. This setup is general and compatible with Google Colab (T4 GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5defa-adae-403b-a890-751d489416ab",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Motivation and Background\n",
    "- The Problem: Traditional RAG evaluations rely on lexical overlap or ROUGE scores, which miss semantic correctness.\n",
    "- The Solution: Nugget evaluation, originally proposed in TREC QA 2003, revived by AutoNuggetizer, uses semantically atomic facts (â€œnuggetsâ€) to evaluate answers.\n",
    "- Inspiration: This library reimplements a simplified, local version of AutoNuggetizer with modular hooks into PyTerrier and HuggingFace models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421df4f6-9dda-45b7-9de6-464cd3313fca",
   "metadata": {},
   "source": [
    "## âš™ï¸ Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5d1de-738e-422b-9680-fa58dc3cc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/MattiWe/ir_datasets.git@add-msmarco-v2.1-trec-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2ebd4-f984-4ec3-aabb-6e5adca3a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/terrier-org/pyterrier@hf-upload-fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda75f3-f54f-46c1-8635-6888b41002fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyterrier_t5 pyterrier_pisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1c6a1-8a49-436f-80b6-39b1634c9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/terrierteam/pyterrier_rag.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275f3bc-b007-4ae6-a04b-a906c83be541",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --no-deps ../."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe713d5c-c5f6-4f84-8429-740f2cab3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from pyterrier_rag.backend import Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11648e98-66ab-487f-998e-fab8d232c8ba",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c43bcb-63d3-40af-98d5-0918f370ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "dataset = ir_datasets.load('msmarco-segment-v2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94859fe6-63f4-495a-b51c-18058d795fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_dataset = pt.get_dataset(\"irds:msmarco-segment-v2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bc72d-8861-4f58-a2b6-6b0a4f2c4cc4",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5944f7-91b8-468d-bd92-b66a0305e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_segment(run):\n",
    "    run = run.rename(columns={\"segment\": \"text\"})\n",
    "    return run\n",
    "rename_pipe = pt.apply.generic(rename_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c9fa9-963a-4370-9c9f-1c805bed29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier_alpha as pta\n",
    "from pyterrier_pisa import PisaIndex\n",
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "\n",
    "index = pta.Artifact.load('namawho/msmarco-segment-v2.1.pisa')\n",
    "bm25_ret = index.bm25() >> pt.text.get_text(pt_dataset, \"segment\") >> rename_pipe\n",
    "\n",
    "monoT5 = MonoT5ReRanker(batch_size=64, verbose=False)\n",
    "monoT5_ret = bm25_ret % 10 >> monoT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8907a2d-0870-40d0-827f-0cbf37ecaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_index = pta.Artifact.from_hf('namawho/msmarco-segment-v2.1.pisa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf39de-7eb2-4c4d-95d7-567d2223aaa9",
   "metadata": {},
   "source": [
    "# Building a baseline retrieval run to generate baseline nuggets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7a963-1f70-4b5f-85c3-820f8089e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"namawho/trec-raggy-dev\")[\"validation\"].to_pandas()\n",
    "topics_df  = dataset[[\"qid\", \"query\"]]\n",
    "answers_df = dataset[[\"qid\", \"query\", \"gold_answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1e4a1-24d9-42bb-9a26-ffae53ca5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = (monoT5_ret)(topics_df.head(10))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b0d35-68e3-4918-97a9-440209c0d7b3",
   "metadata": {},
   "source": [
    "# Nuggetizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428aa08-c6ce-4f9f-962d-e69791e08f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_rag.backend import HuggingFaceBackend\n",
    "\n",
    "backend =  HuggingFaceBackend(\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\",\n",
    "                                          max_new_tokens=2048,\n",
    "                                          model_args={\n",
    "                                              \"device_map\": \"cuda\"\n",
    "                                          }\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0516ff-760b-46d0-b1c7-ccc3e3fd9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastchat.conversation import register_conv_template, get_conv_template, Conversation, SeparatorStyle\n",
    "\n",
    "register_conv_template(\n",
    "    Conversation(\n",
    "        name=\"meta-llama-3.1-sp\",\n",
    "        system_message=\"\",\n",
    "        roles=(\"user\", \"assistant\"),\n",
    "        sep_style=SeparatorStyle.ADD_COLON_SINGLE,\n",
    "        sep=\"\\n\",\n",
    "        messages=[],\n",
    "    )\n",
    ")\n",
    "\n",
    "conv_template = get_conv_template(\"meta-llama-3.1-sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15180598-f175-4882-8c1b-44232c8a76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_csv(path, content):\n",
    "    content.to_csv(path, index=False)\n",
    "\n",
    "def load_csv(path):\n",
    "    try:\n",
    "        content = pd.read_csv(path)\n",
    "        return content\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0c3eb-3896-4f50-adc8-eaef610d51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_nuggetizer.nuggetizer import Nuggetizer\n",
    "\n",
    "nuggetizer = Nuggetizer(\n",
    "    backend=backend, \n",
    "    conversation_template=conv_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "nuggets = load_csv(\"nuggets.csv\")\n",
    "if nuggets is None:\n",
    "    nuggets = nuggetizer.create(baseline)\n",
    "    save_csv(\"nuggets.csv\", nuggets)\n",
    "\n",
    "scored_nuggets = load_csv(\"scored_nuggets.csv\")\n",
    "if scored_nuggets is None:\n",
    "    scored_nuggets = nuggetizer.score(nuggets)\n",
    "    save_csv(\"scored_nuggets.csv\", scored_nuggets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e6935-f55d-4b68-a9cf-e517e9f20727",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8df853-4120-442c-ad08-6ccd743bbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_rag.prompt import Concatenator\n",
    "from pyterrier_rag.readers import Reader\n",
    "\n",
    "reader = Reader(backend)\n",
    "rag_pipeline = monoT5_ret % 3 >> Concatenator() >> reader\n",
    "\n",
    "(monoT5_ret % 3 >> Concatenator() >> reader)(topics_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050527d-4725-4be2-88bc-ebb3debe9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuggetizer.VitalScore().iter_calc(baseline, scored_nuggets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea85e93-6c63-4105-9f48-58be6b4d8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier_rag.measures\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [\n",
    "        rag_pipeline\n",
    "    ],\n",
    "    topics_df.head(2), \n",
    "    answers_df,\n",
    "    [pyterrier_rag.measures.F1, nuggetizer.VitalScore()],\n",
    "    #batch_size=25,\n",
    "    names=['baseline retriever'],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nuggetizer]",
   "language": "python",
   "name": "conda-env-nuggetizer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
